Метод обратного распространения ошибки

Текущая версия страницы пока не проверялась опытными участниками и может значительно отличаться от версии, проверенной 27 октября 2017; проверки требуют 12 правок.
Метод обратного распространения ошибки (англ. backpropagation) — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона. Впервые метод был описан в 1974 г. А. И. Галушкиным[1], а также независимо и одновременно Полом Дж. Вербосом[2]. Далее существенно развит в 1986 г. Дэвидом И. Румельхартом, Дж. Е. Хинтоном и Рональдом Дж. Вильямсом[3] и независимо и одновременно С.И. Барцевым и В.А. Охониным (Красноярская группа)[4]. Это итеративный градиентный алгоритм, который используется с целью минимизации ошибки работы многослойного перцептрона и получения желаемого выхода.

Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы. Барцев и Охонин предложили сразу общий метод («принцип двойственности»), приложимый к более широкому классу систем, включая системы с запаздыванием, распределённые системы, и т. п.[5]

Для возможности применения метода обратного распространения ошибки передаточная функция нейронов должна быть дифференцируема. Метод является модификацией классического метода градиентного спуска.

Содержание
1	Сигмоидальные функции активации
2	Функция оценки работы сети
3	Описание алгоритма
4	Алгоритм
4.1	Режимы реализации
5	Математическая интерпретация обучения нейронной сети
6	Недостатки алгоритма
6.1	Паралич сети
6.2	Локальные минимумы
6.3	Размер шага
7	Литература
8	Ссылки
9	Примечания
Сигмоидальные функции активации
Наиболее часто в качестве функций активации используются следующие виды сигмоид:

Функция Ферми (экспоненциальная сигмоида):

{\displaystyle f(s)={\frac {1}{1+e^{-2\alpha s}}}} f(s)={\frac {1}{1+e^{-2\alpha s}}}
Рациональная сигмоида (при {\displaystyle \alpha =0} \alpha =0 вырождается в т. н. пороговую функцию активации):

{\displaystyle f(s)={\frac {s}{|s|+\alpha }}} f(s)={\frac {s}{|s|+\alpha }}
Гиперболический тангенс:

{\displaystyle f(s)=\mathrm {th} \,{\frac {s}{\alpha }}={\frac {e^{\frac {s}{\alpha }}-e^{-{\frac {s}{\alpha }}}}{e^{\frac {s}{\alpha }}+e^{-{\frac {s}{\alpha }}}}}} f(s)=\mathrm {th} \,{\frac {s}{\alpha }}={\frac {e^{\frac {s}{\alpha }}-e^{-{\frac {s}{\alpha }}}}{e^{\frac {s}{\alpha }}+e^{-{\frac {s}{\alpha }}}}},
где {\displaystyle s} s — выход сумматора нейрона, {\displaystyle \alpha } \alpha  — произвольная константа.

Менее всего, сравнительно с другими сигмоидами, процессорного времени требует расчёт рациональной сигмоиды. Для вычисления гиперболического тангенса требуется больше всего тактов работы процессора. Если же сравнивать с пороговыми функциями активации, то сигмоиды рассчитываются очень медленно. Если после суммирования в пороговой функции сразу можно начинать сравнение с определённой величиной (порогом), то в случае сигмоидальной функции активации нужно рассчитать сигмоид (затратить время в лучшем случае на три операции: взятие модуля, сложение и деление), и только потом сравнивать с пороговой величиной (например, нулём). Если считать, что все простейшие операции рассчитываются процессором за примерно одинаковое время, то работа сигмоидальной функции активации после произведённого суммирования (которое займёт одинаковое время) будет медленнее пороговой функции активации как 1:4.

Функция оценки работы сети
В тех случаях, когда удаётся оценить работу сети, обучение нейронных сетей можно представить как задачу оптимизации. Оценить — означает указать количественно, хорошо или плохо сеть решает поставленные ей задачи. Для этого строится функция оценки. Она, как правило, явно зависит от выходных сигналов сети и неявно (через функционирование) — от всех её параметров. Простейший и самый распространённый пример оценки — сумма квадратов расстояний от выходных сигналов сети до их требуемых значений:

{\displaystyle H={\tfrac {1}{2}}\sum _{\tau \in v_{\mathrm {out} }}(Z(\tau )-Z^{*}(\tau ))^{2}} H = \tfrac{1}{2} \sum_{\tau \in v_\mathrm{out}} (Z(\tau) - Z^*(\tau))^2 ,
где {\displaystyle Z^{*}(\tau )} Z^*(\tau) — требуемое значение выходного сигнала.

Метод наименьших квадратов далеко не всегда является лучшим выбором оценки. Тщательное конструирование функции оценки позволяет на порядок повысить эффективность обучения сети, а также получать дополнительную информацию — «уровень уверенности» сети в даваемом ответе[6].

Описание алгоритма

Архитектура многослойного перцептрона
Алгоритм обратного распространения ошибки применяется для многослойного перцептрона. У сети есть множество входов {\displaystyle x_{1},...,x_{n}} x_1, ..., x_n, множество выходов Outputs и множество внутренних узлов. Перенумеруем все узлы (включая входы и выходы) числами от 1 до N (сквозная нумерация, вне зависимости от топологии слоёв). Обозначим через {\displaystyle w_{i,j}} w_{i,j} вес, стоящий на ребре, соединяющем i-й и j-й узлы, а через {\displaystyle o_{i}} o_i — выход i-го узла. Если нам известен обучающий пример (правильные ответы сети {\displaystyle t_{k}} t_k, {\displaystyle k\in \mathrm {Outputs} } k \in \mathrm{Outputs}), то функция ошибки, полученная по методу наименьших квадратов, выглядит так:

{\displaystyle E(\{w_{i,j}\})={\tfrac {1}{2}}\!\!\sum _{k\in \mathrm {Outputs} }\!\!\!(t_{k}-o_{k})^{2}} E(\{w_{i,j}\}) = \tfrac{1}{2} \!\! \sum_{k \in \mathrm{Outputs}} \!\!\! (t_k - o_k)^2 
Как модифицировать веса? Мы будем реализовывать стохастический градиентный спуск, то есть будем подправлять веса после каждого обучающего примера и, таким образом, «двигаться» в многомерном пространстве весов. Чтобы «добраться» до минимума ошибки, нам нужно «двигаться» в сторону, противоположную градиенту, то есть, на основании каждой группы правильных ответов, добавлять к каждому весу {\displaystyle w_{i,j}} w_{i,j}

{\displaystyle \Delta w_{i,j}=-\eta {\frac {\partial E}{\partial w_{i,j}}}} \Delta w_{i,j} = -\eta \frac {\partial E}{\partial w_{i,j}},
где {\displaystyle 0<\eta <1} 0 < \eta < 1 — множитель, задающий скорость «движения».

Производная считается следующим образом. Пусть сначала {\displaystyle j\in \mathrm {Outputs} } j \in \mathrm{Outputs}, то есть интересующий нас вес входит в нейрон последнего уровня. Сначала отметим, что {\displaystyle w_{i,j}} w_{i,j} влияет на выход сети только как часть суммы {\displaystyle S_{j}=\sum _{i}w_{i,j}x_{i}} S_j = \sum_{i} w_{i,j}x_{i}, где сумма берётся по входам j-го узла. Поэтому

{\displaystyle {\cfrac {\partial E}{\partial w_{i,j}}}={\cfrac {\partial E}{\partial S_{j}}}\,{\cfrac {\partial S_{j}}{\partial w_{i,j}}}=x_{i}{\cfrac {\partial E}{\partial S_{j}}}} \cfrac{\partial E}{\partial w_{i,j}} = \cfrac{\partial E}{\partial S_j}\, \cfrac{\partial S_j}{\partial w_{i,j}} = x_{i} \cfrac{\partial E}{\partial S_j} 
Аналогично, {\displaystyle S_{j}} S_j влияет на общую ошибку только в рамках выхода j-го узла {\displaystyle o_{j}} o_j (напоминаем, что это выход всей сети). Поэтому

{\displaystyle {\cfrac {\partial E}{\partial S_{j}}}={\cfrac {\partial E}{\partial o_{j}}}\,{\cfrac {\partial o_{j}}{\partial S_{j}}}=\left({\cfrac {\partial }{\partial o_{j}}}\,{\cfrac {1}{2}}\sum _{k\in \mathrm {Outputs} }(t_{k}-o_{k})^{2}\right)\!\!\left({\cfrac {\partial \operatorname {f} (S)}{\partial S}}\mid _{S=S_{j}}\right)=} \cfrac{\partial E}{\partial S_j} = \cfrac{\partial E}{\partial o_j}\,\cfrac{\partial o_j}{\partial S_j} = \left (\cfrac{\partial}{\partial o_j}\,\cfrac{1}{2}\sum_{k \in \mathrm{Outputs}}(t_k - o_k)^2 \right ) \!\! \left (\cfrac{\partial \operatorname{f}(S)}{\partial S}\mid_{S=S_j} \right) =
{\displaystyle =\left({\cfrac {1}{2}}\,{\cfrac {\partial }{\partial o_{j}}}(t_{j}-o_{j})^{2}\right)(o_{j}(1-o_{j}))2\alpha =-2\alpha o_{j}(1-o_{j})(t_{j}-o_{j}).} = \left ( \cfrac{1}{2}\, \cfrac{\partial}{\partial o_j}(t_j - o_j)^2 \right) (o_j(1 - o_j)) 2\alpha =
- 2 \alpha o_j(1 - o_j)(t_j - o_j).
где {\displaystyle f(S)} f(S) — соответствующая сигмоида, в данном случае — экспоненциальная

{\displaystyle {\frac {\partial {({\frac {1}{1+e^{-2\alpha S}}})}}{\partial {S}}}={\frac {-1}{(1+e^{-2\alpha S})^{2}}}\times {\frac {\partial {(1+e^{-2\alpha S})}}{\partial {S}}}={\frac {-1}{(1+e^{-2\alpha S})^{2}}}\times (-2\alpha e^{-2\alpha S})=} \frac{\partial{(\frac{1}{1+e^{-2\alpha S}})}}{\partial{S}} = \frac{-1}{(1+e^{-2\alpha S})^2} \times \frac{\partial{(1+e^{-2\alpha S})}}{\partial{S}} = \frac{-1}{(1+e^{-2\alpha S})^2} \times (-2\alpha e^{-2\alpha S}) = 
{\displaystyle ={\frac {2\alpha e^{-2\alpha S}}{(1+e^{-2\alpha S})^{2}}}=\left({\frac {1+e^{-2\alpha S}}{(1+e^{-2\alpha S})^{2}}}-{\frac {1}{(1+e^{-2\alpha S})^{2}}}\right)\times 2\alpha =2\alpha (\operatorname {f} (S)-\operatorname {f^{2}} (S))} {\displaystyle ={\frac {2\alpha e^{-2\alpha S}}{(1+e^{-2\alpha S})^{2}}}=\left({\frac {1+e^{-2\alpha S}}{(1+e^{-2\alpha S})^{2}}}-{\frac {1}{(1+e^{-2\alpha S})^{2}}}\right)\times 2\alpha =2\alpha (\operatorname {f} (S)-\operatorname {f^{2}} (S))}
Если же j-й узел — не на последнем уровне, то у него есть выходы; обозначим их через Children(j). В этом случае

{\displaystyle {\cfrac {\partial E}{\partial S_{j}}}=\sum _{k\in \mathrm {Children} (j)}{\cfrac {\partial E}{\partial S_{k}}}\,{\cfrac {\partial S_{k}}{\partial S_{j}}}} \cfrac{\partial E}{\partial S_j} = \sum_{k \in \mathrm{Children}(j)} \cfrac{\partial E}{\partial S_k}\, \cfrac{\partial S_k}{\partial S_j} ,
и

{\displaystyle {\cfrac {\partial S_{k}}{\partial S_{j}}}={\cfrac {\partial S_{k}}{\partial o_{j}}}\,{\cfrac {\partial o_{j}}{\partial S_{j}}}=w_{j,k}{\cfrac {\partial o_{j}}{\partial S_{j}}}=2\alpha w_{j,k}o_{j}(1-o_{j})} \cfrac{\partial S_k}{\partial S_j} = \cfrac{\partial S_k}{\partial o_j}\, \cfrac{\partial o_j}{\partial S_j} = w_{j,k} \cfrac{\partial o_j}{\partial S_j} = 2\alpha w_{j,k}o_j(1 - o_j).
Но {\displaystyle {\cfrac {\partial E}{\partial S_{k}}}} \cfrac{\partial E}{\partial S_k} — это в точности аналогичная поправка, но вычисленная для узла следующего уровня. Будем обозначать её через {\displaystyle \delta _{k}} \delta _k — от {\displaystyle \Delta _{k}} \Delta _k она отличается отсутствием множителя {\displaystyle (-\eta x_{i,j})} (-\eta x_{i,j}). Поскольку мы научились вычислять поправку для узлов последнего уровня и выражать поправку для узла более низкого уровня через поправки более высокого, можно уже писать алгоритм. Именно из-за этой особенности вычисления поправок алгоритм называется алгоритмом обратного распространения ошибки (backpropagation). Краткое резюме проделанной работы:

для узла последнего уровня
{\displaystyle \delta _{j}=-2\alpha o_{j}(1-o_{j})(t_{j}-o_{j})} \delta _j = -2\alpha o_j(1 - o_j)(t_j - o_j)

для внутреннего узла сети
{\displaystyle \delta _{j}=2\alpha o_{j}(1-o_{j})\!\!\sum _{k\in \mathrm {Children} (j)}\!\!\delta _{k}w_{j,k}} \delta _j = 2\alpha o_j(1 - o_j) \!\! \sum_{k \in \mathrm{Children}(j)} \!\! \delta _k w_{j,k}

для всех узлов
{\displaystyle \Delta w_{i,j}=-\eta \delta _{j}o_{i}} \Delta w_{i,j} = -\eta \delta _j o_{i} ,

где {\displaystyle o_{i}} o_{i} это тот же {\displaystyle x_{i}} x_{i} в формуле для {\displaystyle {\cfrac {\partial E}{\partial w_{i,j}}}} \cfrac{\partial E}{\partial w_{i,j}}.

Получающийся алгоритм представлен ниже. На вход алгоритму, кроме указанных параметров, нужно также подавать в каком-нибудь формате структуру сети. На практике очень хорошие результаты показывают сети достаточно простой структуры, состоящие из двух уровней нейронов — скрытого уровня (hidden units) и нейронов-выходов (output units); каждый вход сети соединён со всеми скрытыми нейронами, а результат работы каждого скрытого нейрона подаётся на вход каждому из нейронов-выходов. В таком случае достаточно подавать на вход количество нейронов скрытого уровня.

Алгоритм
Алгоритм: BackPropagation {\displaystyle (\eta ,\alpha ,\{x_{i}^{d},t^{d}\}_{i=1,d=1}^{n,m},{\textrm {steps}})} {\displaystyle (\eta ,\alpha ,\{x_{i}^{d},t^{d}\}_{i=1,d=1}^{n,m},{\textrm {steps}})}

Инициализировать {\displaystyle \{w_{ij}\}_{i,j}} \{w_{ij}\}_{i,j}  маленькими случайными значениями, {\displaystyle \{\Delta w_{ij}\}_{i,j}=0} \{\Delta w_{ij}\}_{i,j} = 0
Повторить NUMBER_OF_STEPS раз:
.Для всех d от 1 до m:
Подать {\displaystyle \{x_{i}^{d}\}} \{x_i^d\} на вход сети и подсчитать выходы {\displaystyle o_{i}} o_i каждого узла.
Для всех {\displaystyle k\in Outputs} k \in Outputs
{\displaystyle \delta _{k}=o_{k}(1-o_{k})(t_{k}-o_{k})} {\displaystyle \delta _{k}=o_{k}(1-o_{k})(t_{k}-o_{k})}.
Для каждого уровня l, начиная с предпоследнего:
Для каждого узла j уровня l вычислить
{\displaystyle \delta _{j}=o_{j}(1-o_{j})\sum _{k\in Children(j)}\delta _{k}w_{j,k}} \delta _j = o_j(1 - o_j)\sum_{k \in Children(j)} \delta _k w_{j,k}.
Для каждого ребра сети {i, j}
{\displaystyle \Delta w_{i,j}(n)=\alpha \Delta w_{i,j}(n-1)+(1-\alpha )\eta \delta _{j}o_{i}} {\displaystyle \Delta w_{i,j}(n)=\alpha \Delta w_{i,j}(n-1)+(1-\alpha )\eta \delta _{j}o_{i}}.
{\displaystyle w_{i,j}(n)=w_{i,j}(n-1)+\Delta w_{i,j}(n)} {\displaystyle w_{i,j}(n)=w_{i,j}(n-1)+\Delta w_{i,j}(n)}.
Выдать значения {\displaystyle w_{ij}} w_{ij}.
где {\displaystyle \alpha } \alpha  — коэффициент инерциальности для сглаживания резких скачков при перемещении по поверхности целевой функции

Режимы реализации
Существует два режима реализации метода обратного распространения ошибки：

Стохастического (stochastic) градиентного спуска
Пакетного (batch) градиентного спуска
Для пакетного градиентного спуска функция потерь вычисляется для всех образцов вместе взятых после окончания эпохи, и потом вводятся поправки весовых коэффициентов нейрона в соответствии с методом обратного распространения ошибки.

Стохастический метод немедленно после вычисления выхода сети на одном образце вводит поправки в весовые коэффициенты.

Пакетный метод более быстрый и стабильный, но он имеет тенденцию останавливаться и застревать в локальных минимумах. Поэтому для выхода из локальных минимумов нужно использовать особые приёмы, например, алгоритм имитации отжига.

Стохастический метод медленнее, но от того, что он не осуществляет точного градиентного спуска, а вносит «шумы», используя недовычисленный градиент, он способен выходить из локальных минимумов и может привести к лучшему результату.

В виде компромисса рекомендуют также применять мини-пакеты, когда поправка искомых весов осуществляется после обработки нескольких образцов (мини-пакета), то есть, реже чем при стохастическом спуске, но чаще чем при пакетном.

Математическая интерпретация обучения нейронной сети
На каждой итерации алгоритма обратного распространения весовые коэффициенты нейронной сети модифицируются так, чтобы улучшить решение одного примера. Таким образом, в процессе обучения циклически решаются однокритериальные задачи оптимизации.

Обучение нейронной сети характеризуется четырьмя специфическими ограничениями, выделяющими обучение нейросетей из общих задач оптимизации: астрономическое число параметров, необходимость высокого параллелизма при обучении, многокритериальность решаемых задач, необходимость найти достаточно широкую область, в которой значения всех минимизируемых функций близки к минимальным. В остальном проблему обучения можно, как правило, сформулировать как задачу минимизации оценки. Осторожность предыдущей фразы («как правило») связана с тем, что на самом деле нам неизвестны и никогда не будут известны все возможные задачи для нейронных сетей, и, быть может, где-то в неизвестности есть задачи, которые несводимы к минимизации оценки. Минимизация оценки — сложная проблема: параметров астрономически много (для стандартных примеров, реализуемых на РС — от 100 до 1000000), адаптивный рельеф (график оценки как функции от подстраиваемых параметров) сложен, может содержать много локальных минимумов.

Недостатки алгоритма
Несмотря на многочисленные успешные применения обратного распространения, оно не является универсальным решением. Больше всего неприятностей приносит неопределённо долгий процесс обучения. В сложных задачах для обучения сети могут потребоваться дни или даже недели, она может и вообще не обучиться. Причиной может быть одна из описанных ниже.

Паралич сети
В процессе обучения сети значения весов могут в результате коррекции стать очень большими величинами. Это может привести к тому, что все или большинство нейронов будут функционировать при очень больших значениях OUT, в области, где производная сжимающей функции очень мала. Так как посылаемая обратно в процессе обучения ошибка пропорциональна этой производной, то процесс обучения может практически замереть. В теоретическом отношении эта проблема плохо изучена. Обычно этого избегают уменьшением размера шага η, но это увеличивает время обучения. Различные эвристики использовались для предохранения от паралича или для восстановления после него, но пока что они могут рассматриваться лишь как экспериментальные.

Локальные минимумы

Метод градиентного спуска может застрять в локальном минимуме так и не попав в глобальный минимум
Обратное распространение использует разновидность градиентного спуска, то есть осуществляет спуск вниз по поверхности ошибки, непрерывно подстраивая веса в направлении к минимуму. Поверхность ошибки сложной сети сильно изрезана и состоит из холмов, долин, складок и оврагов в пространстве высокой размерности. Сеть может попасть в локальный минимум (неглубокую долину), когда рядом имеется гораздо более глубокий минимум. В точке локального минимума все направления ведут вверх, и сеть неспособна из него выбраться. Основную трудность при обучении нейронных сетей составляют как раз методы выхода из локальных минимумов: каждый раз выходя из локального минимума снова ищется следующий локальный минимум тем же методом обратного распространения ошибки до тех пор, пока найти из него выход уже не удаётся.

Проблемы отсутствия выпуклости в функции ошибок и как следствие трудности с локальными минимумами и плоскими участками считались недостатком метода, однако Ян Лекун в обзорной статье 2015 года утверждает, что с практической точки зрения эти явления не так опасны.[7]

Размер шага
Внимательный разбор доказательства сходимости[3] показывает, что коррекции весов предполагаются бесконечно малыми. Ясно, что это неосуществимо на практике, так как ведёт к бесконечному времени обучения. Размер шага должен браться конечным. Если размер шага фиксирован и очень мал, то сходимость слишком медленная, если же он фиксирован и слишком велик, то может возникнуть паралич или постоянная неустойчивость. Эффективно увеличивать шаг до тех пор, пока не прекратится улучшение оценки в данном направлении антиградиента и уменьшать, если такого улучшения не происходит. П. Д. Вассерман[8] описал адаптивный алгоритм выбора шага, автоматически корректирующий размер шага в процессе обучения. В книге А. Н. Горбаня[9] предложена разветвлённая технология оптимизации обучения.

Следует также отметить возможность переобучения сети, что является скорее результатом ошибочного проектирования её топологии. При слишком большом количестве нейронов теряется свойство сети обобщать информацию. Весь набор образов, предоставленных к обучению, будет выучен сетью, но любые другие образы, даже очень похожие, могут быть классифицированы неверно.